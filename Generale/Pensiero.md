# Pensiero
## La probabilità - Psicologia del Pensiero

1. **Bayes**  

2. Legge dei grandi numeri - *Gambler fallacy* o *legge dei piccoli numeri*

**Twersky & Kahneman**

> Esperimento ospedale  
**Winefield** dimostra che l'effetto scompare quando viene mostrato ai soggetti che diversi eventi sono indipendenti:  

> La Gambler fallacy potrebbe quindi essere legata alla considerazione di lanci come un insieme di eventi legati, *e che la nostra idea di caso si basi su una sorta di regolarità compensatoria*  

3. Probabilità condizionale  

> Esperimento 3 scatole  
I soggetti non si rendono conto che l'apertura della prima scatola **non è casuale** bensí condizionata, perché applicano:  

- Uniformity belief -> Equiprobabilità delle restanti alternative
- No-news, no-change belief -> Sapere che una scatola è vuota non aggiunge informazioni, quindi non varia le probabilità

Macchi e Girotto hanno modificato la presentazione dell'esperimento esprimendo la condizionalità dell'apertura di B (luci rosse o verdi), ottenendo la risposta corretta dalla maggioranza dei soggetti  

4. La fallacia della probabilità di base - base-rate fallacy

**Tversky e Kahneman**  

Problemi di giudizio sociale  
*o quando non ti danno cazzo le probabilità*

- Avvocati e Ingegneri  
    30/70 vs 70/30, 5 CV casuali, euristiche *tipicità e rappresentatività*  
    Dick ha un CV casuale, distribuzione 50 e 50  
    Koehler scopre che dipende dalla presentazione di Dick  

Problemi scolastici  
*o quando ti danno le cazzo probabilità ma cazzo non si capisce un cazzo*  

Probabilità di base: frequenza relativa ad un evento  
Informazione specifica (*likelihood*): probabilità relativa ad un sottogruppo  

- Taxi  
    85/15 verdi/blu, testimone blu 80/20  
    La ggente considera solo l'ultima informazione  
    La spiegazione è che all'informazione di frequenza non viene attribuita causalità  
    Versione causale, dove non c'è frequenza dei taxi ma frequenza dei taxi coinvolti in incidenti (incompetenza autisti)  

- Suicidi  
    80/20 sposati/single  
    suicidi 3 volte maggiori tra i single  
    Probabilità suicida di essere single  
    Viene ancora considerata solo l'ultima info  (x un solo elemento *causale*)

- Libri  
    80/20 tedesco/francese  
    tascabili 3 volte più alti in francese  
    Probabilità tascabile di essere francese  
    61% di risposte bayesiane (x nessun elemento *causale*) 

- Suicidio causale  
    tentati suicidi 80/20 ragazze/i  
    Suicidi riusciti 3 volte più alti tra i maschi  
    Probabilità morto suicida maschio 
    Maggiore parte risposte bayesiane (x entrambi elementi *causali*)

**L'approccio frequentistico**  

**Gigerenzer** sostiene che il concetto di probabilità non sia applicabile ad eventi singoli, spiegando così la *base rate fallacy*

- Esperimento della malattia  
    Incidenza 1/1000  
    Falsi positivi 5% 
    Richiesta probabilità positivo = malato
    ~ metà rispondono 95% / 18% rispondono 0.02 (bayes) 

Secondo **Gigerenzer Cosmides e Tooby** questo è spiegato dal fatto che vengono usate probabilità e non frequenze.  

- Replica esperimento malattia con frequenze  
    1 su 1000 affetto da malattia  
    50 falsi positivi su 1000  
    Campione casuale di 1000 persone, quante di queste risultando positive sono ammalate?  


Critiche:  

> 1 su 51 non è la risposta matematicamente corretta, come non lo è 1 su 50  
Introduzione omogeneità dei dati -> minor carico computazionale sui soggetti  

- Versione non omogenea di Macchi e Mosconi  
    1 su 1000 malato  
    su 100 5 falsi positivi ecc..  
    Ottengono meno risposte corrette di Cosmides  
    **Confutata ipotesi frequentistica**  

- Versione computazionalmente più difficile di Macchi e Mosconi
    Cambiano i falsi positivi, 85 su 1000  
    Ottengono ancora meno risposte corrette  
    **Forse è il carico computazionale la variabile interessante**

**L'approccio pragmatico**: l'idea di *formulazione partitiva*  
Cerca una spiegazione migliore per la base rate fallacy rispetto alla rilevanza causale (Tversky e Kahneman)
Nella versione causale del problema dei suicidi era *impossibile* considerare i suicidi senza la *base rate* dei tentati suicidi

La formulazione partitiva ha il triplice effetto di:  

1. Consentire di identificare l'insieme di riferimento dei dati
2. Eliminare la confusione fra probabilità condizionali
3. Consentire di percepire la relazione fra i dati

Ogni esperimento riformulato per qualche motivazione viene a dare risultati positivi solo e solo se viene riformulato (anche se incidentalmente) in termini partitivi.  

**La sovrastima delle proprie risposte**  

Le persone hanno una percezione esagerata delle proprie risposte corrette in compiti come di cultura generale o previsione di eventi.  

- *Hard-easy* effect  
    Diminuisce l'overconfidence via via che il compito diventa facile fino a diventare *underconfidence*  

Viene spiegato dallo **strenght and weight model** di Griffin e Tversky  

- Forza dell'informazione:  
    Quanto sono estremi i dati a favore  
    *Numero di volte in cui esce testa*
- Peso dell'informazione:  
    Validità predittiva del dato  
    *Ampiezza del campione*  

Secondo gli autori i soggetti non considerano il *peso*, o meglio si basano sulla *forza* e poi aggiustano insufficientemente in base al peso.  

Euristiche utilizzate:  

- Rappresentatività 
- Ancoramento 
- Aggiustamento 

**Critiche**  

Secondo **May**, i test utilizzati non sono rappresentativi, perché generano *overconfidence* per come sono strutturati (+ nord Roma o NY)  

**Gigerenzer et al.** creano sulla base della critica la **Teoria dei modelli mentali probabilistici (PMM)**  

Secondo il PMM i soggetti hanno dei modelli mentali legati tra loro attraverso probabilità.  
Inoltre per rispondere alla domanda *"A quante di queste domande pensi di aver risposto correttamente"* si attiva un modello differente da quello attivo per ogni singola risposta, rendendo **inutile la domanda,** o meglio facendo sì che questa misuri un altro costrutto.  

**Fallacia dell'intersezione**  - **Conjunction fallacy**  

Esperimento di Linda  

Spiegato dai frequentisti dicendo che essendo un evento singolo non era applicabile il concetto di frequenza.  

**Tversky e Kahnemman** testano quest'ipotesi e trovano che funziona.  

**Fiedler** riporta risultati diversi a seconda del problema  

Secondo l'**approccio pragmatico** la domanda di per sé è anomala, e chiedere se un elemento appartenga a C vs C + F dove F appartiene a C fa sì che i soggetti ***percepiscano C come implicitamente C - F***  

Quest'ipotesi è comprovata da Polizer e Noveck e da Mosconi e Macchi  

## La probabilità - Manuale  

**Euristiche**  

- Secondo Duncker  
    Procedimenti per raggiungere la soluzione di un problema, *inerente all'essenza del problema*
- Secondo Simon  
    Procedimenti economici per risolvere problemi
- Secondo Tversky e Kahneman  
    Procedimenti semplificati *che obbediscono a meccanismi loro propri* portando ad errori 

**Spiegazioni Errori**  

- Secondo Tversky e Kahneman  
    **Causalità**  

- Secondo Macchi  
    **Pragmatica**

## Decisione - Psicologia del Pensiero  

Processo di selezione  

**Approccio normativo**  

> Modello decisionale razionale

**Approccio descrittivo**  

> Costruire modelli in grado di prevedere e spiegare decisioni umane  

Le decisioni **variano** secondo più dimensioni:  

- Rischio
- Numero di attributi (per le quali le alternative differiscono)
- Numero di stadi (multipli vs singolo)

**Valore atteso**: Vincita x P di vincita - Perdita x P di perdita  
**Utilità attesa**: Come valore atteso, ma esprime la percezione soggettiva di valore  

**Teoria dell'utilità**  - Von Neumann e Morgestern  

Il comportamento di un individuo può dirsi razionale e massimizzante dell'utilità attesa se rispetta i seguenti assiomi (e altri):  

- Principio della transitività delle preferenze  
    A > B & B > C -> A > C  
    
- Principio di indipendenza  
    Se uno stato conduce ad un esito indipendentemente dalla scelta, allora la scelta dovrebbe essere effettuata indipendentemente dall'esito

Tversky - Esperimento ABCDE e Accessori macchine

Lichtenstein e Slovic - Esperimento scommesse:  

| 99% vinci 4$ | 1% perdi 1$ |
| ------------ | ----------- |
| 33% vinci 16$ | 67% perdi 2$ |  

I soggetti preferiscono la scommessa sicura tra le due  

Ma dovendo valutare le singole scommesse preferiscono quella meno sicura  

*Risultati inspiegabili per la teoria normativa* 

Slovic e Kahneman osservarono che *nel compito di scelta i soggetti prestano maggiore attenzione alla probabilità di vincere, mentre in quello di valutazione alla somma della vincita*  

Una spiegazione più articolata era stata fornita da Tversky Sattah e Slovic con l'**ipotesi della ponderazione contingente** secondo la quale *i soggetti ponderano gli attributi secondo i quali sono descritte le scelte in maniera contingente al compito*  

**Il paradosso di Allais**  

- Dilemma A:  

1. 100% x 1000$
2. 89% x 1000$ + 10% x 5000$ + 0% x 0$

- Dilemma B

1. 11% x 1000$ + 89% x 0$
2. 10% x 5000$ + 90% x 0$

**Esperimenti sul Principio di indipendenza** - Tversky e Shafir  

> Studenti universitari dopo un esame passato vs fallito vs incerto  
Vacanza alle Hawaii ad un prezzo molto conveniente  

La maggioranza degli studenti con esito sicuro *sia passato che fallito* accettavano, mentre solo 1/3 di quelli con esito incerto accettavano.  

*Incapacità della mente umana di pensare in modo consequenziale*  

**La Teoria del Prospetto** - Kahneman e Tversky  

Teoria descrittiva, tenta di compensare le mancanze della *teoria dell'utilità*, ma si distanzia da questa per:  

1. Utilità diventa **Valore**  
    Benessere raggiungibile diventa **Guadagni e perdite da una posizione neutra di partenza**, inoltre il valore è descritto da una sinusoide  

2. La probabilità non è più oggettiva  
    Ma quelle basse vengono sovrastimate e quelle alte sottostimate  

**Esperimenti**  

- Problema 1  

A) 1 su 1000 x 5000$  
B) 100% x 5$  

3/4 scelgono **A**  
*Ovvero sovrastimano la bassa probabilità di vincita* come le persone che giocano al lotto

- Problema 2 

C) 1 su 1000 x - 5000$  
D) 100% - 5$  

4/5 scelgono **D**
*Ovvero sovrastimano la bassa probabilità di avere una grossa perdita* come le persone che assicurano cose improbabili  

3. I guadagni vengono trattati con poco rischio e le perdite con più rischio  

- Problema 3

Ti vengono dati 1000$, scegli:  

A) 50% di vincere altri 1000$  
B) 100% di vincere altri 500$  

- Problema 4

Ti vengono dati 2000$, scegli:

C) 50% di perdere 1000$  
D) 100% di perdere 500$

**Sunk Costs**  

Esperimento del presidente della compagnia di aerei  

> Progetto in corso al 90%  
90 milioni investiti vs no info 
Prospetto negativo sul successo del progetto  
Tieni 10 milioni o finisci?

La spesa iniziale viene percepita come perdita nel momento in cui non si finisce il progetto, e viene quindi preferito finirlo *solo* nel caso in cui si conosca l'informazione sul prezzo del progetto.  

**L'effetto di incorniciamento**  

Esperimenti di Trevsky e Kahneman (Malattia cinese e Terapia polmonare)  

Quando il problema è presentato in termini di perdita aumenta la propensione al rischio.  

**Teoria dell'utilità multi-attributiva**  - Von Winterfeldt e Edwards
Descrive il comportamento degli individui nelle decisioni multi-attributive, nelle quale gli attributi sono:  

- Difficili da individuare
- Mutevoli
- Troppi per la memoria di lavoro  

Quindi è inapplicabile il *processo razionale* di:  

1. Individuazione
2. Attribuzione di pesi
3. Calcolo finale  

In queste situazioni gli individui si affidano ad *euristiche*  

Secondo **Simon** si cerca un *livello minimo accettabile* di soddisfazione, adattivo ai valori medi presenti sul mercato.  

Le strategie di decisione si dividono in 

- Compensatorie (In cui gli attributi sono confrontabili tra loro)   
    1. Addittiva -> *processo razionale*
- Non compensatorie  
    1. Lessicografica -> Consideri solo l'attributo più importante
    2. Eliminazione per aspetti -> Gerarchia di attributi e poi eliminazione per soglia

Gli individui preferirebbero **Strategie compensatorie**, ma definire un ordine gerarchico tra gli attributi è molto cognitivamente dispendioso, quindi:  

- Fino a 2 attributi si usa la *strategia addittiva o modello lineare*
- Altrimenti usa strategie non compensatorie 

Questo può variare in funzione del:  

1. Disponibilità cognitiva del soggetto
2. Tempo a disposizione
3. Somiglianza tra i diversi attributi

**Rappresentazione del compito**  

**Contabilità Mentale** - Tversky e Kahneman  

Problemi:  

- biglietto teatrale: Perdi biglietto vs Perdi ammontare pari al biglietto, compri il biglietto?
- Acquisto calcolatrice e giacca: sconto di 5$ su una vs l'altra a 20 minuti in macchina, ci vai?

Vengono ipotizzate diverse rappresentazioni mentali che tengono separate spese diverse e le valutano individualmente  

## Categorizzazione  - Psicologia del Pensiero

**Formazione**  

**Funzione**  

1. Economia Cognitiva
2. Inferenze

*Esperimento corvo, pipistrello e fenicottero*  

**La teoria classica**  

- Intensione vs Estensione dei concetti
- Formazione per condivisione di attributi (Hull, Bruner)

*Problemi*:  

> Estrema definizione -> Poco realistica  
Nessuna distinzione tra categorie naturali e artificiali (autoformate e artificiose)  

> **Wittgennstein** ritiene che le categorie si formino per *somiglianza di famiglia*, ovvero insiemi di fattori che si sovrappongono  

**Critiche formali**  alla teoria classica  

1. Non tiene conto della possibilità che cambino le caratteristiche costitutive degli esemplari (tigre erbivora o senza gambe, è ancora una tigre?)
2. Non permette di discernere tra categorie vuote coerenti (unicorno) e non
3. Non tiene conto della discordanza entro e tra i soggetti nella categorizzazione e ricategorizzazione
4. Pollo più simile alla categoria più lontana (animale) che alla sovraordinata (uccello) 
5. Tipicità 

**La teoria del prototipo** 

Grado di tipicità = Livello di somiglianza ad un prototipo *reale* (Rosch) o *astratto* (Smith, Shoben e Rips)  

Prove empiriche (maggiore velocità nella categorizzazione e nell'inferenza quando si usano esemplari più tipici)  

Livelli:  

- Sovraordinato
- Base (maggiore diversificazione)
- Subordinato  

La massima *cue validity* è nelle categorie base, perché nelle sovraordinate c'è più intersezione e nelle subordinate meno differenziazione  

**Critiche**  
Non è presente il concetto di *somiglianza funzionale*, ovvero di somiglianza non percettiva ma relativa agli attributi funzionali propri delle categorie sovraordinate di appartenenza  

Inoltre considerare come prototipo l'*esemplare medio* risulta controverso, per esempio nella c. sovraordinata 'mobili'  

*È necessaria un ripensamento del concetto di somiglianza*  

**Rosch, Simpson e Miller** sostengono che ci sia una gerarchia di attributi dai quali si inferisce somiglianza o dissomiglianza *ma* per fare ciò bisognerebbe avere una previa categorizzazione. (Per me può essere un processo graduale)  

Un altro punto critico è l'esistenza di categorie di oggetti orientati ad un fine, dove è inesistente somiglianza tra i membri (regali adatti ad un compleanno)  

Esperimento di Rips - Monete e pizza di diametro 7.5cm  

Viene rilevata la dualità di alcuni concetti (numeri dispari) che sembrano essere definiti in maniera non prototipica ma manifestano tempi di reazione differenti in base alla grandezza (Secondo me perché ci metti più tempo ad elaborare numeri più grandi, per difficoltà computazionali e per inferiore disponibilità)  

Quindi viene definito:  

- *Core* come cuore concettuale della categoria
- *Prototipo* come elementi percettivi salienti per l'identificazione

Il Core si differenzia dalla definizione classica di descrizione perché è **mutabile**, e serve a *stabilizzare* i concetti ancorandoli oltre alla dimensione percettiva  

**Le teorie ingenue**  
Murphy e Medin ipotizzano che le categorie siano *"teorie"* che le persone si costruiscono per raggruppare determinati eventi attraverso relazioni causali tra insiemi di attributi.  

La premessa filosofica di questa ipotesi è la teoria della spiegazione di Putnam, secondo la quale i concetti non *descrivono*, ma sono "*teorie*", che non necessitano della conoscenza né della parola né dell'oggetto alla quale si riferiscono  

I concetti si dividono in diverse tipologie:  

- Naturali  
    Cercano di descrivere la natura ultima delle cose, adattandosi alla scienza
- Nominali  
    Vengono utilizzati in maniera attributiva, convenzionale
- Artefatti  
    Sono una via di mezzo

Persone con diversi livelli di conoscenza modificano le loro categorie di conseguenza.  

**Nakamura** effettua esperimenti per provare la tesi che *fornendo spiegazioni causali gli individui apprendono più facilmente nuove categorie*  

La nozione di somiglianza di per sé non ha capacità esplicative, ma è soltanto un **effetto**  

Per **Medin e Ortony** gli attributi più accessibili sono i primi ad essere acquisiti, ma essendo inestricabilmente legati a quelli genetici e profondi non avviene contrasto  

Per **Quine** c'è una progressione tra categorizzazione basata su somiglianza e basata su teorie  

**Carey** fa esperimenti sui bambini (scimmia vera e giocattolo) che lo portano alla conclusione che anche loro utilizzino teorie prototipiche con core legati alla biologia  

\* *altre teorie che ignoreremo* *  

**Modello funzionalista di Barslou**  

Le categorie sono **instabili** e definite in base alla *funzione*, relativa al contesto, anziché alla *struttura* del concetto di riferimento

Inoltre le strutture con gradazione non riflettono le variazioni, perché queste possono essere determinate da differenze culturali  

Il modello descrive la categorizzazione come un processo che utilizza le conoscenze interrelate e continue della memoria a lungo termine per costruire e elaborare i concetti nella memoria di lavoro.  
Sulla base di ciò la mdl costruisce concetti in relazione ai contesti, concetti a loro volta immagazzinati in mlt.  

## Problem Solving - Pensiero + Mosconi  

**Simon** Labirinto = Problem solving  

Distinzione tra ***compito*** (cannibali e missionari) e ***problema***  (4 palline e bilancia, compravendita del cavallo, ristorante, 9 punti)  

Nei problemi il soggetto contribuisce alla creazione del problema *accettando* il discorso come un *buon* discorso  

C'è differenza nelle reazioni dei soggetti in caso di fallimento, quando viene loro rivelata la soluzione 

Il *Problem Solving* sono i tentativi del soggetto di risolvere i problemi  

Nei compiti questo inizia nel momento in cui problema e soggetto si incontrano  

Nei problemi bisogna considerare la *costituzione* del problema  

Nella teoria dominante:  

- Non c'è distinzione tra problema e compito
- Viene data più importanza ai compiti
- Non viene considerata la costituzione
- Non vengono considerati i processi che portano al fallimento

Fasi del problema:  

- Messaggio dato
- Decodifica  
    - Codice legale  
        - Soluzione
    - Codice naturale  
        - Contraddizione
        - Ricodifica

Il problema nasce da un'***asimmetria tra la codifica e la decodifica***  
La soluzione si può ottenere solo **cambiando codice**  

A volte i problemi sono composti, e sono composti anche da una parte di *compito*, detta *residuo del problema*  

Inoltre anche i compiti possono diventare problemi in modo utile (Giovane Gauss) o inutile (quando si cerca di risolvere le cose in modo "intelligente")  

Nell'autoposizione del problema non c'è *doppio codice*, ovvero si passa da linguaggio naturale a legale autonomamente.  

*In natura non ci sono problemi*, essi sono solo nella nostra mente.  


**Rapporto tra parola e pensiero**  

Differenza tra messaggio dato e messaggio effettivo, attraverso la decodificazione primaria  

**Problemi di Luria e Cvetkova**  

Problemi sottoposti a pazienti con lesioni cerebrali  

- Bambino ha 12 mele, ne regala e gliene restano 8, quante ne ha regalate?  
    È un *problema semplice invertito*

**Mosconi** sottopone gli stessi problemi a bambini.  

**La tesi** è che la difficoltà vari in base alla struttura retorica  

Problema come discorso costituito da due parti:  

- Enunciato
- Domanda

La domanda corrisponde al focus  

I residui narrativi interferiscono:  
*Ne ha regalate alcune ad un amico* non fornisce dati  

Dal punto di vista **retorico**, l'inserimento di informazioni non rilevanti è una *violazione* delle regole implicite della retorica  

Può avvenire quindi un fenomeno analogo alla *iperregolarizzazione* dei verbi, che porta i soggetti a *riempire* la proposizione vuota, confondendola con la successiva (ne ha regalate 8 ad un amico).  

Nel caso dei bambini molti evitano il problema, di quelli che lo provano il 40% fallisce nel modo previsto  

Solo 1/4 del 60% dei risolutori ha risolto il problema al primo tentativo, sempre per la motivazione sopra esposta.  

Ad altri soggetti è stato presentato il compito di *ripetizione* del problema e invenzione di uno analogo, e hanno presentato quasi tutto lo slittamento  

Si trovano conferme dei protocolli di Luria  

**Le versioni pseduo-parallele**  

**Differenziazione sintattica**  
*Un bambino aveva 12 mele. Dopo averne regalate alcune a un amico, gliene restano 8. Quante ne ha regalate?*  

75% soluzioni corrette.  

**Differenziazione topologica**  
*Un bambino ha regalato a un amico alcune delle sue mele. Aveva 12 mele. Gliene restano 8. Quante ne ha regalate?*  

80% soluzioni corrette.  
Solo 10% evitano il problema contro il 20% degli altri casi  

Secondo Luria la difficoltà sta nella **Massima differenza dallo schema abituale**
*Quante mele ha regalato al suo amico un bambino che ne aveva 12 e gliene restano 8?*  

90% risposte corrette.  

**Secondo problema**: *Pietro ha 4 mele e Paolo 2 in più. Quante ne hanno in tutto?*  

La caratteristica importante è che è impossibile risolverlo con un solo atto  

20% risposte corrette.  

Fallimenti dovuti a incapacità di comprendere *"2 in più"*  

**Versione semplificata**  
*Pietro ha 4 mele e Paolo 2 in più. Quante ne ha Paolo?*  

70% di risposte corrette.  

Ipotesi esclusa.  
Forse la differenza dipende dal grado di complessità.  


**Versione Pseudo-parallela**  
*Pietro ha 4 mele e Paolo 4 + 2. Quante ne hanno in tutto?*    

73% di risposte corrette.  

Ipotesi esclusa.

Il motivo della difficoltà è nella focalizzazione ellittica, che fa sì che il problema secondario passi in secondo piano e venga semplificato, inoltre il "di più" suggerisce erroneamente ai soggetti di sommare i due addendi

**Versione Pseudo-parallela 2**  
*Pietro ha 4 mele e Paolo ne ha* **quante** *Pietro e 2 di più. Quante ne hanno in tutto?*  

70% risposte corrette.  

**Le Ragioni del discorso**  

Problema delle 3 scatole con 2 palline  

15% risposte corrette.  
25% risposte corrette dopo suggerimento.  

La struttura del discorso-problema (enunciato e domanda) e la struttura del discorso-soluzione (centrazione e sviluppo) sono differente:  
Nella prima si parla solo di palline, nella seconda sono centrali le etichette.  

Ciò è provato dal fatto che cambiando il testo (ci sono 3 scatole, una con l'etichetta con scritto ecc...) i risultati sono i seguenti:  

60% risposte corrette.  

Se oltre all'enunciato si cambia la richiesta le risposte corrette arrivano a 75%  

**Il discorso tende però ad assumere naturalmente la prima organizzazione** quando per esempio viene chiesto di descrivere ai soggetti il processo di preparazione dell'esperimento.  

**L'ordine**  

Viene percepito come uno stato superiore e conclusivo.  

Secondo Wertheimer l'ordine corrisponde alla soluzione, ma questo non sempre è vero.  

Esperimento della foglia e del lago  
Esperimento dei 24 panini  

Si cerca l'ordine, ma non solo percettivamente, bensì all'interno dei processi di pensiero.  
Ciò fa sì che si perda il riferimento temporale in determinati casi (
"un panino a testa" che può diventare "uno al giorno" e poi tornare ad essere "uno a testa")

**Il discorso del non solutore**  

Secondo alcuni autori  

> *il soggetto scompone il problema in problemi semplici e li risolve parallelamente, andando per tentativi*, **accumulando** *così sempre più informazioni*  

Secondo altri autori  

> *La soluzione si ottiene attraverso una* **riorganizzazione**, *e nonostante questa si presenti come all'improvviso, in realtà è il risultato di una linea coerente di pensiero*  

Tutti questi autori studiano i **solutori**, dimenticando che in ogni problema c'è sempre una difficoltà, ovvero *insuccessi almeno temporanei*  

Per studiare i non solutori verranno utilizzati protocolli  

**Problema delle 3 scatole - Protocolli**  

- I non solutori iniziano sempre con un tentativo casuale, un *"andare a vedere"* incongruo con la necessità del problema di inferire implicitamente il contenuto delle scatole.  
- I soggetti non riescono ad effettuare inferenze oltre a quelle direttamente conseguenti dall'azione appena effettuata  
- La comparsa di **discorsi vacui** può essere indice di non soluzione  
- A volte i soggetti *rovesciano* la situazione trattando le etichette come ignote e le palline come note, vanificando la struttura del problema, ovvero rendendo tutto noto, non avendo così più nulla da risolvere.  
- Si trovano inoltre incoerenze nell'applicazione di informazioni utili suggerite, come l'uso corretto delle etichette nel primo caso ma l'incapacità di farlo in altri (Secondo me limiti della memoria di lavoro, che portano ad inadatta semplificazione del concetto)

**Ristrutturazione e Processo** - **Wertheimer e Duncker**  

I problemi  

- Di Wertheimer: Cosa succede nel momento in cui il pensiero diventa produttivo?
- Di Duncker: Cosa porta il pensiero ad essere produttivo?

Wertheimer è spesso frainteso nel suo riferirsi ai processi di pensiero come *sequela di tentativi*.  
Per lui infatti significa semplicemente **atto di pensiero intelligente**  

Dunker costruisce *alberi genealogici* delle soluzioni, raccogliendo da uno o più protocolli le proposte di soluzione (Problema della cura del tumore attraverso irradiazione)  

Inoltre Wertheimer non tiene neanche i protocolli (Mosconi vuole dire che Duncker è più simpatico)  

Anche secondo Simon e Newell Duncker è figo, infatti tutta la loro human information processing è ~~una copia spudorata~~ tratta dal suo pensiero  

La rappresentazione del compito avviene trasformando la *task environment* nel *problem space* personale attraverso 3 filtri:  

1. Definizione delle norme legali
2. Definizione dell'obiettivo
3. Interazione con i limiti della memoria di lavoro



